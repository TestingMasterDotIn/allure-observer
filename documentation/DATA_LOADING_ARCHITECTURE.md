# Allure Test Observability Dashboard - Data Loading Architecture

## Overview

This document explains the core data loading mechanism of the Allure Test Observability Dashboard, including how JSON files are loaded, processed, and transformed into actionable insights. Understanding this architecture is crucial for maintaining, extending, and optimizing the application.

## Core Concept

The dashboard consumes **Allure Framework report data** - a collection of JSON files generated by Allure after test execution. These files contain raw test execution data that gets transformed into rich analytics and visualizations.

## Allure JSON File Structure

### Primary Data Files

The dashboard expects these specific JSON files from Allure reports:

| File | Purpose | Key Data |
|------|---------|----------|
| `behaviors.json` | Test execution data | Test results, status, timing, parameters |
| `categories.json` | Test categorization | Error categories, groupings, hierarchical data |
| `packages.json` | Package/module structure | Test organization by packages |
| `suites.json` | Test suite information | Suite-level groupings and metadata |
| `timeline.json` | Execution timeline | Thread execution, concurrency data |

### File Content Examples

**behaviors.json structure:**
```json
{
  "children": [
    {
      "name": "TestClassName",
      "status": "passed|failed|broken|skipped",
      "time": {
        "start": 1747066563267,
        "stop": 1747066566267,
        "duration": 3000
      },
      "duration": 3000,
      "uid": "unique-test-id",
      "parameters": ["param1", "param2"],
      "statusDetails": {
        "message": "Error message",
        "trace": "Stack trace"
      }
    }
  ]
}
```

**categories.json structure:**
```json
{
  "uid": "category-root",
  "name": "categories",
  "children": [
    {
      "name": "Test defects",
      "children": [
        {
          "name": "Connection Error",
          "children": [
            {
              "name": "ActualTestName",
              "uid": "test-uid",
              "status": "failed",
              "time": { "start": 123, "stop": 456, "duration": 333 }
            }
          ]
        }
      ]
    }
  ]
}
```

## Data Loading Flow

```mermaid
graph TD
    A[User Settings] --> B{Data Source Type}
    B -->|Local| C[File System Access API]
    B -->|FTP| D[FTP Service]
    
    C --> E[scanLocalFolder()]
    D --> F[ftpService.downloadAllureFiles()]
    
    E --> G[Raw JSON Files]
    F --> G
    
    G --> H[parseBehaviors.js]
    H --> I[transformAllureData()]
    I --> J[TestData Interface]
    J --> K[Dashboard Components]
    
    K --> L[Dashboard Page]
    K --> M[Timeline Page]
    K --> N[Test Explorer]
    K --> O[Failures Page]
    K --> P[History Page]
```

## Key Components & Files

### 1. Data Loading Services

#### File Service (`src/services/fileService.ts`)
- **Purpose**: Handles local file system access
- **Key Function**: `scanLocalFolder()`
- **Technology**: File System Access API (Chrome/Edge)
- **Process**:
  1. Uses `window.showDirectoryPicker()` to select folder
  2. Recursively scans for required JSON files
  3. Reads file contents and parses JSON
  4. Returns structured data arrays

```typescript
// Key function signature
export const scanLocalFolder = async (): Promise<{
  behaviors: BehaviorsData[];
  categories: CategoriesData[];
  packages: PackagesData[];
  suites: SuitesData[];
  timeline: TimelineData[];
}>
```

#### FTP Service (`src/services/ftpService.ts`)
- **Purpose**: Handles remote FTP server access
- **Key Function**: `downloadAllureFiles()`
- **Technology**: basic-ftp library (with mock implementation)
- **Process**:
  1. Connects to FTP server with credentials
  2. Lists files in remote directory
  3. Downloads each required JSON file
  4. Parses content and returns structured data

```typescript
// Key function signature
async downloadAllureFiles(config: FtpConfig): Promise<{
  behaviors: BehaviorsData[];
  categories: CategoriesData[];
  packages: PackagesData[];
  suites: SuitesData[];
  timeline: TimelineData[];
}>
```

### 2. Data Parsing & Transformation

#### JSON Parsers (`src/utils/parseBehaviors.ts`)
- **Purpose**: Parse and validate raw JSON files
- **Functions**:
  - `parseBehaviorsJson()` - Validates and parses behaviors.json
  - `parseCategoriesJson()` - Handles categories.json
  - `parsePackagesJson()` - Processes packages.json
  - `parseSuitesJson()` - Parses suites.json
  - `parseTimelineJson()` - Handles timeline.json

#### Data Transformer (`src/utils/dataTransformerNew.ts`)
- **Purpose**: Convert raw data into dashboard-ready format
- **Key Function**: `transformAllureData()`
- **Process**:
  1. Extracts tests from nested JSON structures
  2. Calculates statistics (totals, percentages, durations)
  3. Builds date ranges and threading information
  4. Creates performance metrics
  5. Returns unified `TestData` interface

```typescript
// Transformation process
export const transformAllureData = (data: {
  behaviors: BehaviorsData[];
  categories: CategoriesData[];
  packages: PackagesData[];
  suites: SuitesData[];
  timeline: TimelineData[];
}): TestData => {
  // Extract tests from all sources
  // Calculate statistics
  // Build analytics data
  // Return unified format
}
```

### 3. Data Context & State Management

#### Data Context (`src/context/DataContext.tsx`)
- **Purpose**: Global state management for test data
- **Key Hook**: `useTestData()`
- **State**:
  - `testData`: Transformed test data
  - `dataSource`: Current data source configuration
  - `loading`: Loading state
  - `filteredTests`: Filtered test results

```typescript
// Context interface
interface DataContextType {
  testData: TestData | null;
  setTestData: (data: TestData | null) => void;
  dataSource: DataSource;
  setDataSource: (source: DataSource) => void;
  isLoading: boolean;
  setIsLoading: (loading: boolean) => void;
}
```

### 4. Type Definitions

#### Core Types (`src/types/behaviors.ts`)
- **TestBehavior**: Individual test case data
- **TestData**: Complete dashboard data structure
- **DataSource**: Configuration for data sources
- **FtpConfig**: FTP connection settings

```typescript
// Key interfaces
export interface TestBehavior {
  name: string;
  status: 'passed' | 'failed' | 'broken' | 'skipped';
  time: TestTime;
  duration: number;
  uid?: string;
  // ... additional fields
}

export interface TestData extends ParsedTestData {
  flakiness?: Flakiness;
  failureClusters?: FailureClusterData;
  retryAnalysis?: RetryAnalysis;
  performanceMetrics?: PerformanceMetrics;
}
```

## Data Flow Sequence

### 1. User Configuration
```
Settings Page → Data Source Selection → Save Configuration
```

### 2. Data Loading Trigger
```
Load Data Button → loadDataFromSource() → Service Selection
```

### 3. File Retrieval
```
Local: scanLocalFolder() → File System API → JSON Files
FTP: downloadAllureFiles() → FTP Connection → Remote Files
```

### 4. Data Processing
```
Raw JSON → parseBehaviors.js → Validation → transformAllureData()
```

### 5. State Update
```
Transformed Data → DataContext → Component Re-render
```

### 6. Dashboard Rendering
```
TestData → Dashboard Components → Analytics & Visualizations
```

## Error Handling & Validation

### File Validation
- **Missing Files**: Graceful handling when files are absent
- **Invalid JSON**: Error catching and user notification
- **Schema Validation**: Type checking for expected data structures

### Data Integrity
- **Null Checks**: Defensive programming for missing properties
- **Time Validation**: Ensuring valid timestamp data
- **Status Validation**: Verifying test status values

### User Feedback
- **Loading States**: Visual indicators during data processing
- **Error Messages**: Clear communication of issues
- **Progress Tracking**: Status updates during long operations

## Performance Considerations

### Optimization Strategies
1. **Lazy Loading**: Components load data only when needed
2. **Memoization**: `useMemo` for expensive calculations
3. **Filtering**: Early filtering to reduce data processing
4. **Chunking**: Processing large datasets in chunks

### Memory Management
- **Data Cleanup**: Proper cleanup of large datasets
- **Component Unmounting**: Cleanup on route changes
- **Storage Limits**: localStorage size considerations

## Extension Points & Improvement Areas

### 1. Data Sources
**Current**: Local files, FTP servers  
**Potential Extensions**:
- HTTP/REST API endpoints
- Cloud storage (AWS S3, Google Cloud)
- Database connections (MongoDB, PostgreSQL)
- CI/CD pipeline integration (Jenkins, GitHub Actions)

### 2. File Format Support
**Current**: Allure JSON format  
**Potential Extensions**:
- JUnit XML reports
- TestNG XML reports
- Cucumber JSON reports
- Custom JSON schemas
- CSV/Excel import

### 3. Real-time Data
**Current**: Manual loading  
**Potential Extensions**:
- WebSocket connections for live updates
- Polling mechanisms for auto-refresh
- Event-driven updates from CI/CD systems
- File system watchers for local directories

### 4. Data Processing
**Current**: Client-side transformation  
**Potential Extensions**:
- Server-side processing for large datasets
- Worker threads for heavy computations
- Streaming data processing
- Data compression and optimization

### 5. Caching & Performance
**Current**: In-memory storage  
**Potential Extensions**:
- IndexedDB for large datasets
- Service worker caching
- Data pagination and virtualization
- Background data prefetching

### 6. Analytics Enhancement
**Current**: Basic statistics and visualizations  
**Potential Extensions**:
- Machine learning for pattern detection
- Predictive analytics for test failures
- Advanced statistical analysis
- Custom metric calculations

## Configuration Examples

### Local File Loading
```typescript
// Settings configuration
const dataSource = {
  type: 'local'
};

// File structure expected:
// /allure-results/
//   ├── behaviors.json
//   ├── categories.json
//   ├── packages.json
//   ├── suites.json
//   └── timeline.json
```

### FTP Server Loading
```typescript
// FTP configuration
const ftpConfig = {
  host: 'ftp.example.com',
  port: 21,
  user: 'username',
  password: 'password',
  remotePath: '/allure-results'
};
```

## Troubleshooting

### Common Issues
1. **File Access Denied**: Browser security, HTTPS requirement
2. **Invalid JSON**: Malformed Allure output files
3. **Missing Files**: Incomplete Allure report generation
4. **Large Files**: Memory limitations with huge datasets
5. **Network Issues**: FTP connection problems

### Debugging Tools
- Browser DevTools for network inspection
- Console logging throughout the data pipeline
- Error boundaries for component-level error handling
- Data validation checkpoints

## Security Considerations

### Data Privacy
- No sensitive data stored permanently
- Local processing reduces data exposure
- FTP credentials handling best practices

### Browser Security
- File System Access API limitations
- CORS considerations for remote data
- Content Security Policy compliance

## Conclusion

The data loading architecture is designed to be flexible, extensible, and robust. The modular design allows for easy addition of new data sources, file formats, and processing capabilities. Understanding this flow is essential for:

- **Developers**: Adding new features and data sources
- **DevOps**: Integrating with CI/CD pipelines
- **Analysts**: Understanding data limitations and capabilities
- **Contributors**: Identifying optimization opportunities

The architecture supports the dashboard's goal of providing comprehensive test observability while maintaining performance and user experience.
